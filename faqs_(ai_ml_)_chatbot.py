# -*- coding: utf-8 -*-
"""FAQs (Ai/ML ) Chatbot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WUNB28WjbG6pPqstwdL7q8wM6f1wx7BF
"""

#Installing required libraries
!pip install pandas sentence-transformers gradio

#Importing Libraries

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util
import gradio as gr
from google.colab import files

#Uploading FAQs Dataset in CSV Format

uploaded = files.upload()
faq_df = pd.read_csv(list(uploaded.keys())[0])
faq_df.head()

#Loading Sentence Transformer Model
model = SentenceTransformer('all-MiniLM-L6-v2')

#Precomputing embeddings for all FAQ questions

faq_questions = faq_df['Question'].tolist()
faq_answers = faq_df['Answer'].tolist()
faq_embeddings = model.encode(faq_questions, convert_to_tensor=True)

#Chatbot logic (semantic search)

def chatbot_response(user_input):
    user_embedding = model.encode(user_input, convert_to_tensor=True)
    similarity = util.cos_sim(user_embedding, faq_embeddings)[0]
    idx = int(similarity.argmax())  # Best match index
    response = faq_answers[idx]
    return response

#Building Chatbot UI with Gradio
with gr.Blocks(css=".gradio-container {background-color: #111; color: white; font-family: 'Arial';}") as demo:
    gr.Markdown("<h1 style='text-align:center; color:cyan;'>ðŸ’¬ AI-Powered FAQ Chatbot</h1>")

    chatbot = gr.Chatbot(height=400)
    msg = gr.Textbox(placeholder="Ask me anything...", label="Your Question")
    clear = gr.Button("Clear Chat")

    def respond(message, chat_history):
        response = chatbot_response(message)
        chat_history.append((message, response))
        return "", chat_history

    msg.submit(respond, [msg, chatbot], [msg, chatbot])
    clear.click(lambda: None, None, chatbot, queue=False)

demo.launch()